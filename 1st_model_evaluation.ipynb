{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "197f0040-9671-4907-ab52-473b9b5a77a8",
   "metadata": {},
   "source": [
    "## Model Evaluation for 1st Proactive Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf32c43-34d2-46c2-8b86-a49e53fdd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for model evaluation\n",
    "import os\n",
    "import gc\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a93e0-52a3-445b-bf98-640d283e7f0d",
   "metadata": {},
   "source": [
    "#### Loading the models and test sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89fbdc0-411d-44fb-8d35-b660ea8b69d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/rb/model_rb.keras\n",
      "The model has an optimizer, indicating it has been trained.\n",
      "The model has 1660033 parameters.\n",
      "\n",
      "\n",
      "Model loaded from models/gl/model_gl.keras\n",
      "The model has an optimizer, indicating it has been trained.\n",
      "The model has 1660033 parameters.\n",
      "\n",
      "\n",
      "Model loaded from models/tc/model_tc.keras\n",
      "The model has an optimizer, indicating it has been trained.\n",
      "The model has 1660033 parameters.\n"
     ]
    }
   ],
   "source": [
    "# Loading the models\n",
    "model_rb = utils.load_and_verify_model(\"models/rb/model_rb.keras\")\n",
    "print(\"\\n\")\n",
    "model_gl = utils.load_and_verify_model(\"models/gl/model_gl.keras\")\n",
    "print(\"\\n\")\n",
    "model_tc = utils.load_and_verify_model(\"models/tc/model_tc.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a557a839-9f00-4538-afea-c7f3e2a7dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the paths\n",
    "base_path = \"data/processed\"\n",
    "datasets = [\"rb\", \"gl\", \"tc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c415ae-6aac-4dd6-a94d-27e93a79ab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test data for rb: (869, 30, 71), (869,)\n",
      "Loaded test data for gl: (869, 30, 71), (869,)\n",
      "Loaded test data for tc: (869, 30, 71), (869,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the test sequences\n",
    "loaded_data = {data: utils.load_sequences(base_path, data, \"test\") for data in datasets}\n",
    "(ted_rb, tel_rb) = loaded_data[\"rb\"]\n",
    "(ted_gl, tel_gl) = loaded_data[\"gl\"]\n",
    "(ted_tc, tel_tc) = loaded_data[\"tc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae787e-af9d-4e46-942f-5170fa8e36f2",
   "metadata": {},
   "source": [
    "#### Model Evaluation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4d8c84a-7e8a-4b80-ac72-11f4bdc682dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_rb = utils.get_predictions(model_rb, ted_rb, \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb22474-9090-4362-8bd4-75790765a200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_gl = utils.get_predictions(model_gl, ted_gl, \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5185e2d1-b448-42ea-9a4b-f23159990d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_tc = utils.get_predictions(model_tc, ted_tc, \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b8ccfe-6ee6-4764-8054-3ab8c415999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved at results/rb/predictions_rb.csv\n",
      "Predictions saved at results/gl/predictions_gl.csv\n",
      "Predictions saved at results/tc/predictions_tc.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the predictions\n",
    "utils.save_predictions_to_csv(predictions_rb, \"results/rb/predictions_rb.csv\", target_names= [\"Robot Protective Stop\"])\n",
    "utils.save_predictions_to_csv(predictions_gl, \"results/gl/predictions_gl.csv\", target_names= [\"Grip Lost\"])\n",
    "utils.save_predictions_to_csv(predictions_tc, \"results/tc/predictions_tc.csv\", target_names= [\"Tool Current\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "007b918d-7fa3-49e5-8368-34c0a654fd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "| Metric    |   Value |\n",
      "+===========+=========+\n",
      "| Accuracy  |  0.9609 |\n",
      "+-----------+---------+\n",
      "| Precision |  0.9233 |\n",
      "+-----------+---------+\n",
      "| Recall    |  0.9609 |\n",
      "+-----------+---------+\n",
      "| F1-Score  |  0.9417 |\n",
      "+-----------+---------+\n",
      "Metrics saved at results/rb/metrics_rb.csv\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation results of the 1st Model \"Robot Protective Stop\" [Classification]\n",
    "metrics_rb = utils.calculate_metrics(tel_rb, predictions_rb, \"classification\")\n",
    "utils.display_metrics(metrics_rb, \"classification\")\n",
    "utils.save_metrics_to_csv(metrics_rb, 'results/rb/metrics_rb.csv', \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc27fb8-8044-4930-b68b-39b3607a24c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "| Metric    |   Value |\n",
      "+===========+=========+\n",
      "| Accuracy  |  0.9839 |\n",
      "+-----------+---------+\n",
      "| Precision |  0.968  |\n",
      "+-----------+---------+\n",
      "| Recall    |  0.9839 |\n",
      "+-----------+---------+\n",
      "| F1-Score  |  0.9759 |\n",
      "+-----------+---------+\n",
      "Metrics saved at results/gl/metrics_gl.csv\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation results of the 2nd Model \"Grip Lost\" [Classification]\n",
    "metrics_gl = utils.calculate_metrics(tel_gl, predictions_gl, \"classification\")\n",
    "utils.display_metrics(metrics_gl, \"classification\")\n",
    "utils.save_metrics_to_csv(metrics_gl, 'results/gl/metrics_gl.csv', \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f666b27e-fade-44e4-9286-685547f31869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "| Metric   |   Value |\n",
      "+==========+=========+\n",
      "| MSE      |  0.0085 |\n",
      "+----------+---------+\n",
      "| RMSE     |  0.0923 |\n",
      "+----------+---------+\n",
      "| MAE      |  0.0524 |\n",
      "+----------+---------+\n",
      "| MAPE     |  0.3973 |\n",
      "+----------+---------+\n",
      "Metrics saved at results/tc/metrics_tc.csv\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation results of the 3rd Model \"Tool Current\" [Regression]\n",
    "metrics_tc = utils.calculate_metrics(tel_tc, predictions_tc, \"regression\")\n",
    "utils.display_metrics(metrics_tc, \"regression\")\n",
    "utils.save_metrics_to_csv(metrics_tc, 'results/tc/metrics_tc.csv', \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca430c18-9b0f-4a76-adf6-19ecc5ce19e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1049"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeing up memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41565cd-e53d-42dd-bda0-eac01390afa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

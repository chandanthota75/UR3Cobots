{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b9d6a2-6616-41f7-ad25-7313c024c301",
   "metadata": {},
   "source": [
    "## Data preprocessing and Model evaluation for 3rd proactive strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94338db5-9add-4f5c-92cd-6f3c8a6d7c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for data preprocessing and model evaluation\n",
    "import os\n",
    "import gc\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935c3091-899a-44f5-8c37-63b926c37006",
   "metadata": {},
   "source": [
    "#### Loading the models, testing data and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b129824a-3298-44b9-9a4a-65b0e0d0bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/rb/model_rb.keras\n",
      "The model has an optimizer, indicating it has been trained.\n",
      "The model has 1660033 parameters.\n",
      "\n",
      "\n",
      "Model loaded from models/gl/model_gl.keras\n",
      "The model has an optimizer, indicating it has been trained.\n",
      "The model has 1660033 parameters.\n",
      "\n",
      "\n",
      "Model loaded from models/tc/model_tc.keras\n",
      "The model has an optimizer, indicating it has been trained.\n",
      "The model has 1660033 parameters.\n"
     ]
    }
   ],
   "source": [
    "# Loading the models\n",
    "model_rb = utils.load_and_verify_model(\"models/rb/model_rb.keras\")\n",
    "print(\"\\n\")\n",
    "model_gl = utils.load_and_verify_model(\"models/gl/model_gl.keras\")\n",
    "print(\"\\n\")\n",
    "model_tc = utils.load_and_verify_model(\"models/tc/model_tc.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfeb8f0-aa31-4eca-8f0e-b1528c848bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test predictions of MVFF models\n",
    "predictions_cj = utils.load_data(\"results/cj/predictions_cj.csv\", \"csv\")\n",
    "predictions_sj = utils.load_data(\"results/sj/predictions_sj.csv\", \"csv\")\n",
    "predictions_tj = utils.load_data(\"results/tj/predictions_tj.csv\", \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5cd2c2-333e-47f5-9bb5-72c9d1b0649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of current joints predictions: (869, 6)\n",
      "Shape of speed joints predictions: (869, 6)\n",
      "Shape of temperature joints predictions: (869, 6)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the predictions\n",
    "print(\"Shape of current joints predictions:\", predictions_cj.shape)\n",
    "print(\"Shape of speed joints predictions:\", predictions_sj.shape)\n",
    "print(\"Shape of temperature joints predictions:\", predictions_tj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a2a090-1263-4889-8bd6-268d7e7462bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the testing data\n",
    "ted_rb = utils.load_data(\"data/processed/rb/test/scaled_test_data_rb.csv\", \"csv\")\n",
    "ted_gl = utils.load_data(\"data/processed/gl/test/scaled_test_data_gl.csv\", \"csv\")\n",
    "ted_tc = utils.load_data(\"data/processed/tc/test/scaled_test_data_tc.csv\", \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08b59ec-eb15-415d-82d8-de7172ca9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test Labels\n",
    "tel_rb = utils.load_data(\"data/processed/rb/test/test_labels_rb.csv\", \"csv\")\n",
    "tel_gl = utils.load_data(\"data/processed/gl/test/test_labels_gl.csv\", \"csv\")\n",
    "tel_tc = utils.load_data(\"data/processed/tc/test/test_labels_tc.csv\", \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33b3386f-f7a6-4adf-8069-297f17460d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of current joints data: (899, 71)\n",
      "Shape of speed joints data: (899, 71)\n",
      "Shape of temperature joints data: (899, 71)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the predictions\n",
    "print(\"Shape of current joints data:\", ted_rb.shape)\n",
    "print(\"Shape of speed joints data:\", ted_gl.shape)\n",
    "print(\"Shape of temperature joints data:\", ted_tc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3352f-7fa9-40a3-b0f3-a112d31d57f4",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec6341c4-32e0-4936-967c-7918aa01c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the columns to replace test columns\n",
    "n_pred = len(predictions_cj)\n",
    "cj_columns = [f'Current_J{i}' for i in range(6)]\n",
    "sj_columns = [f'Speed_J{i}' for i in range(6)]\n",
    "tj_columns = ['Temperature_T0'] + [f'Temperature_J{i}' for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36268dd4-fb2f-487b-a6be-c4db8166562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_rb.loc[:n_pred-1, cj_columns] = predictions_cj.values\n",
    "ted_gl.loc[:n_pred-1, cj_columns] = predictions_cj.values\n",
    "ted_tc.loc[:n_pred-1, cj_columns] = predictions_cj.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9915352-7de7-41f3-80b5-fddeb4426826",
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_rb.loc[:n_pred-1, sj_columns] = predictions_sj.values\n",
    "ted_gl.loc[:n_pred-1, sj_columns] = predictions_sj.values\n",
    "ted_tc.loc[:n_pred-1, sj_columns] = predictions_sj.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4246e0f-3837-4293-a51b-b627c95b0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_rb.loc[:n_pred-1, tj_columns] = predictions_tj.values\n",
    "ted_gl.loc[:n_pred-1, tj_columns] = predictions_tj.values\n",
    "ted_tc.loc[:n_pred-1, tj_columns] = predictions_tj.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce92ca1-b5e5-4f70-9a7a-5ff97801f44c",
   "metadata": {},
   "source": [
    "#### Adding interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7f0b47e-cbe3-4e8f-b1e5-9dec3091c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_rb['Average Temperature'] = ted_rb[[f'Temperature_J{i}' for i in range(1, 6)] + ['Temperature_T0']].mean(axis=1)\n",
    "ted_gl['Average Temperature'] = ted_gl[[f'Temperature_J{i}' for i in range(1, 6)] + ['Temperature_T0']].mean(axis=1)\n",
    "ted_tc['Average Temperature'] = ted_tc[[f'Temperature_J{i}' for i in range(1, 6)] + ['Temperature_T0']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfabd2a0-760d-4b21-946d-3036536e7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_rb['Gradient Temperature'] = (ted_rb[[f'Temperature_J{i}' for i in range(1, 6)] + ['Temperature_T0']].max(axis=1) - \n",
    "                                   ted_rb[[f'Temperature_J{i}' for i in range(1, 6)] + ['Temperature_T0']].min(axis=1))\n",
    "ted_gl['Gradient Temperature'] = (ted_gl[[f'Temperature_J{i}' for i in range(1, 6)] + ['Temperature_T0']].max(axis=1) - \n",
    "                                   ted_gl[[f'Temperature_J{i}' for i in range(1, 6)] + ['Temperature_T0']].min(axis=1))\n",
    "ted_tc['Gradient Temperature'] = (ted_tc[[f'Temperature_J{i}' for i in range(1, 6)] + ['Temperature_T0']].max(axis=1) - \n",
    "                                   ted_tc[[f'Temperature_J{i}' for i in range(1, 6)] + ['Temperature_T0']].min(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86956ec-3541-42c6-b7d1-6fa56803fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_rb['Load Imbalance'] = (\n",
    "    ted_rb[[f'Current_J{i}' for i in range(0, 6)]].max(axis=1) - \n",
    "    ted_rb[[f'Current_J{i}' for i in range(0, 6)]].min(axis=1)) / ted_rb[[f'Current_J{i}' for i in range(0, 6)]].mean(axis=1)\n",
    "ted_gl['Load Imbalance'] = (\n",
    "    ted_gl[[f'Current_J{i}' for i in range(0, 6)]].max(axis=1) - \n",
    "    ted_gl[[f'Current_J{i}' for i in range(0, 6)]].min(axis=1)) / ted_gl[[f'Current_J{i}' for i in range(0, 6)]].mean(axis=1)\n",
    "ted_tc['Load Imbalance'] = (\n",
    "    ted_tc[[f'Current_J{i}' for i in range(0, 6)]].max(axis=1) - \n",
    "    ted_tc[[f'Current_J{i}' for i in range(0, 6)]].min(axis=1)) / ted_tc[[f'Current_J{i}' for i in range(0, 6)]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe28f5-98d6-428d-ad60-e8b3746e9483",
   "metadata": {},
   "source": [
    "#### Creating Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5de9dc1-20ea-4e99-89ff-b8f52f000988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the sequence length value\n",
    "with open(\"data/processed/sequence_length.txt\", \"r\") as file:\n",
    "    sequence_length = int(file.read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9105159-9dee-47e0-94cd-b0c434b094b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sequences for test datasets\n",
    "ted_rb, tel_rb = utils.create_sequences(ted_rb, tel_rb, sequence_length, \"classification\")\n",
    "ted_gl, tel_gl = utils.create_sequences(ted_gl, tel_gl, sequence_length, \"classification\")\n",
    "ted_tc, tel_tc = utils.create_sequences(ted_tc, tel_tc, sequence_length, \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9578202-9cf2-4497-bbac-fb97c200e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data \"Robot Protective Stop\": (869, 30, 71), Test labels \"Robot Protective Stop\": (869, 1)\n",
      "Test data \"Grip Lost\": (869, 30, 71), Test labels \"Grip Lost\": (869, 1)\n",
      "Test data \"Tool Current\": (869, 30, 71), Test labels \"Tool Current\": (869, 1)\n"
     ]
    }
   ],
   "source": [
    "# Checking if the sequences are created properly\n",
    "datasets = {\n",
    "    'Robot Protective Stop': [ted_rb, tel_rb],\n",
    "    'Grip Lost': [ted_gl, tel_gl],\n",
    "    'Tool Current': [ted_tc, tel_tc]\n",
    "}\n",
    "\n",
    "for label, (x_test, y_test) in datasets.items():\n",
    "    print(f\"Test data \\\"{label}\\\": {x_test.shape}, Test labels \\\"{label}\\\": {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "529fec20-bbf8-47d4-804d-e825a5b1d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sequences to: data\\processed\\fesf\\rb\\test\\sequences\n",
      "Saved sequences to: data\\processed\\fesf\\gl\\test\\sequences\n",
      "Saved sequences to: data\\processed\\fesf\\tc\\test\\sequences\n"
     ]
    }
   ],
   "source": [
    "# Saving the numpy arrays\n",
    "arrays = {\n",
    "    \"rb\": {\"test\": (ted_rb, tel_rb)},\n",
    "    \"gl\": {\"test\": (ted_gl, tel_gl)},\n",
    "    \"tc\": {\"test\": (ted_tc, tel_tc)}\n",
    "}\n",
    "\n",
    "for key, splits in arrays.items():\n",
    "    for split, data in splits.items():\n",
    "        folder = f\"data/processed/fesf/{key}/{split}/sequences\"\n",
    "        utils.save_sequences(data, folder, f\"seq_{split}_data_{key}.npy\", f\"seq_{split}_labels_{key}.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4abe0c6-bffb-4360-a217-bc3efa98aa0f",
   "metadata": {},
   "source": [
    "#### Model Evluation and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5914185a-38ea-4432-80f4-cace96ce8862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting the test data on trained models\n",
    "probability_rb = model_rb.predict(ted_rb)\n",
    "probability_gl = model_gl.predict(ted_gl)\n",
    "predictions_tc = model_tc.predict(ted_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef077cfe-bec6-4db9-8d9a-89b0bf8e78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the binary predictions of 1st model and 2nd model\n",
    "predictions_rb = (probability_rb > 0.6).astype(int)\n",
    "predictions_gl = (probability_gl > 0.4).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b96cc46-8e8a-47e4-9d3f-988861426e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved at results/fesf/predictions_fesf_rb.csv\n",
      "Predictions saved at results/fesf/predictions_fesf_gl.csv\n",
      "Predictions saved at results/fesf/predictions_fesf_tc.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the predictions\n",
    "utils.save_predictions_to_csv(predictions_rb, \"results/fesf/predictions_fesf_rb.csv\", target_names= [\"Robot Protective Stop\"])\n",
    "utils.save_predictions_to_csv(predictions_gl, \"results/fesf/predictions_fesf_gl.csv\", target_names= [\"Grip Lost\"])\n",
    "utils.save_predictions_to_csv(predictions_tc, \"results/fesf/predictions_fesf_tc.csv\", target_names= [\"Tool Current\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa93b4cb-9ad7-46b3-9ffd-4a915cce0dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "| Metric    |   Value |\n",
      "+===========+=========+\n",
      "| Accuracy  |  0.9448 |\n",
      "+-----------+---------+\n",
      "| Precision |  0.9227 |\n",
      "+-----------+---------+\n",
      "| Recall    |  0.9448 |\n",
      "+-----------+---------+\n",
      "| F1-Score  |  0.9336 |\n",
      "+-----------+---------+\n",
      "Metrics saved at results/fesf/metrics_fesf_rb.csv\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation results of the 1st Model \"Robot Protective Stop\" [Classification]\n",
    "metrics_rb = utils.calculate_metrics(tel_rb, predictions_rb, \"classification\")\n",
    "utils.display_metrics(metrics_rb, \"classification\")\n",
    "utils.save_metrics_to_csv(metrics_rb, 'results/fesf/metrics_fesf_rb.csv', \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10832304-c587-4971-9c49-d11d814ba4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "| Metric    |   Value |\n",
      "+===========+=========+\n",
      "| Accuracy  |  0.9597 |\n",
      "+-----------+---------+\n",
      "| Precision |  0.9676 |\n",
      "+-----------+---------+\n",
      "| Recall    |  0.9597 |\n",
      "+-----------+---------+\n",
      "| F1-Score  |  0.9637 |\n",
      "+-----------+---------+\n",
      "Metrics saved at results/fesf/metrics_fesf_gl.csv\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation results of the 2nd Model \"Grip Lost\" [Classification]\n",
    "metrics_gl = utils.calculate_metrics(tel_gl, predictions_gl, \"classification\")\n",
    "utils.display_metrics(metrics_gl, \"classification\")\n",
    "utils.save_metrics_to_csv(metrics_gl, 'results/fesf/metrics_fesf_gl.csv', \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b019e54-a2bb-41b4-96fd-fbff7f2f8fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "| Metric   |   Value |\n",
      "+==========+=========+\n",
      "| MSE      |  0.0085 |\n",
      "+----------+---------+\n",
      "| RMSE     |  0.0923 |\n",
      "+----------+---------+\n",
      "| MAE      |  0.0523 |\n",
      "+----------+---------+\n",
      "| MAPE     |  0.397  |\n",
      "+----------+---------+\n",
      "Metrics saved at results/fesf/metrics_fesf_tc.csv\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation results of the 3rd Model \"Tool Current\" [Regression]\n",
    "metrics_tc = utils.calculate_metrics(tel_tc, predictions_tc, \"regression\")\n",
    "utils.display_metrics(metrics_tc, \"regression\")\n",
    "utils.save_metrics_to_csv(metrics_tc, 'results/fesf/metrics_fesf_tc.csv', \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed9fef53-d30e-4600-8351-fdab336c0ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1049"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeing up memory\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

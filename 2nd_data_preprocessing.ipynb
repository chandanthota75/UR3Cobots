{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb98a43f-565d-4346-9570-211a11af96d8",
   "metadata": {},
   "source": [
    "### Data preprocessing for 2nd proactive strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666f0e2c-69fe-4fab-91c8-b2b25d5f0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import gc\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b900d-b469-41a6-b98d-cb92fdf025b1",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e586d44-0b9a-47af-8d63-4385f43e626f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Shape: (7409, 38)\n"
     ]
    }
   ],
   "source": [
    "# Loading the raw dataset\n",
    "data = utils.load_data(\"data/processed/processed_data.csv\", \"csv\")\n",
    "print(f'Dataset loaded. Shape: {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a8aeb19-3343-4be8-956a-37746d96f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after dropping column \"Robot Protective Stop\", \"Grip Lost\" and \"Tool Current\". Shape: (7409, 35)\n"
     ]
    }
   ],
   "source": [
    "# Dropping the columns \"Robot Protective Stop\", \"Grip Lost\" and \"Tool Current\"\n",
    "data = data.drop(columns=[\"Robot Protective Stop\", \"Grip Lost\", \"Tool Current\"])\n",
    "print(f'Dataset after dropping column \"Robot Protective Stop\", \"Grip Lost\" and \"Tool Current\". Shape: {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c519af3c-1b84-4e98-8c54-886ac20c7878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features identified: ['Time Phase', 'Cycle Time', 'Current_J0', 'Current_J1', 'Current_J2', 'Current_J3', 'Current_J4', 'Current_J5', 'Current_Direction_J0', 'Current_Direction_J1', 'Current_Direction_J2', 'Current_Direction_J3', 'Current_Direction_J4', 'Current_Direction_J5', 'Speed_J0', 'Speed_J1', 'Speed_J2', 'Speed_J3', 'Speed_J4', 'Speed_J5', 'Speed_Direction_J0', 'Speed_Direction_J1', 'Speed_Direction_J2', 'Speed_Direction_J3', 'Speed_Direction_J4', 'Speed_Direction_J5', 'Temperature_T0', 'Temperature_J1', 'Temperature_J2', 'Temperature_J3', 'Temperature_J4', 'Temperature_J5', 'Average Temperature', 'Gradient Temperature', 'Load Imbalance']\n",
      "Features Count: 35\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset columns\n",
    "columns = data.columns.tolist()\n",
    "print(\"Features identified:\", columns)\n",
    "print(\"Features Count:\", len(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb329b9-02b7-4821-b11e-64c547aaa8df",
   "metadata": {},
   "source": [
    "#### Spitting the dataset into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ddd12b9-893b-4f32-898a-9c8239f52232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the features and targets from the dataset for the 3 unique target sets\n",
    "features = columns\n",
    "\n",
    "target_cj = [\n",
    "    *[f'Current_J{i}' for i in range(6)]\n",
    "]\n",
    "\n",
    "target_sj = [\n",
    "    *[f'Speed_J{i}' for i in range(6)]\n",
    "]\n",
    "\n",
    "target_tj = [\n",
    "    'Temperature_T0', *[f'Temperature_J{i}' for i in range(1, 6)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9922fc6b-2f36-42dc-a6a7-30bac84e83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable \"Current joints\" dataset - Train feature Shape: (4772, 35), Train target Shape: (4772, 6)\n",
      "Target variable \"Current joints\" dataset - Validation features Shape: (1737, 35), Validation target Shape: (1737, 6)\n",
      "Target variable \"Current joints\" dataset - Test features Shape: (899, 35), Test target Shape: (899, 6)\n",
      "\n",
      "Target variable \"Speed joints\" dataset - Train features Shape: (4772, 35), Train target Shape: (4772, 6)\n",
      "Target variable \"Speed joints\" dataset - Validation features Shape: (1737, 35), Validation target Shape: (1737, 6)\n",
      "Target variable \"Speed joints\" dataset - Test features Shape: (899, 35), Test target Shape: (899, 6)\n",
      "\n",
      "Target variable \"Temperature joints\" dataset - Train features Shape: (4772, 35), Train target Shape: (4772, 6)\n",
      "Target variable \"Temperature joints\" dataset - Validation features Shape: (1737, 35), Validation target Shape: (1737, 6)\n",
      "Target variable \"Temperature joints\" dataset - Test features Shape: (899, 35), Test target Shape: (899, 6)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the datasets into train, test, and validation sets\n",
    "trd_cj, trl_cj, vad_cj, val_cj, ted_cj, tel_cj = utils.split_data(data, features, target_cj)\n",
    "print(f'Target variable \"Current joints\" dataset - Train feature Shape: {trd_cj.shape}, Train target Shape: {trl_cj.shape}')\n",
    "print(f'Target variable \"Current joints\" dataset - Validation features Shape: {vad_cj.shape}, Validation target Shape: {val_cj.shape}')\n",
    "print(f'Target variable \"Current joints\" dataset - Test features Shape: {ted_cj.shape}, Test target Shape: {tel_cj.shape}')\n",
    "\n",
    "trd_sj, trl_sj, vad_sj, val_sj, ted_sj, tel_sj = utils.split_data(data, features, target_sj)\n",
    "print(f'\\nTarget variable \"Speed joints\" dataset - Train features Shape: {trd_sj.shape}, Train target Shape: {trl_sj.shape}')\n",
    "print(f'Target variable \"Speed joints\" dataset - Validation features Shape: {vad_sj.shape}, Validation target Shape: {val_sj.shape}')\n",
    "print(f'Target variable \"Speed joints\" dataset - Test features Shape: {ted_sj.shape}, Test target Shape: {tel_sj.shape}')\n",
    "\n",
    "trd_tj, trl_tj, vad_tj, val_tj, ted_tj, tel_tj = utils.split_data(data, features, target_tj)\n",
    "print(f'\\nTarget variable \"Temperature joints\" dataset - Train features Shape: {trd_tj.shape}, Train target Shape: {trl_tj.shape}')\n",
    "print(f'Target variable \"Temperature joints\" dataset - Validation features Shape: {vad_tj.shape}, Validation target Shape: {val_tj.shape}')\n",
    "print(f'Target variable \"Temperature joints\" dataset - Test features Shape: {ted_tj.shape}, Test target Shape: {tel_tj.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbbd2c64-fe4f-4072-b120-5934db17834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved: data/processed/cj/train\\train_data_cj.csv\n",
      "Dataset saved: data/processed/cj/train\\train_labels_cj.csv\n",
      "Dataset saved: data/processed/cj/valid\\valid_data_cj.csv\n",
      "Dataset saved: data/processed/cj/valid\\valid_labels_cj.csv\n",
      "Dataset saved: data/processed/cj/test\\test_data_cj.csv\n",
      "Dataset saved: data/processed/cj/test\\test_labels_cj.csv\n",
      "Dataset saved: data/processed/sj/train\\train_data_sj.csv\n",
      "Dataset saved: data/processed/sj/train\\train_labels_sj.csv\n",
      "Dataset saved: data/processed/sj/valid\\valid_data_sj.csv\n",
      "Dataset saved: data/processed/sj/valid\\valid_labels_sj.csv\n",
      "Dataset saved: data/processed/sj/test\\test_data_sj.csv\n",
      "Dataset saved: data/processed/sj/test\\test_labels_sj.csv\n",
      "Dataset saved: data/processed/tj/train\\train_data_tj.csv\n",
      "Dataset saved: data/processed/tj/train\\train_labels_tj.csv\n",
      "Dataset saved: data/processed/tj/valid\\valid_data_tj.csv\n",
      "Dataset saved: data/processed/tj/valid\\valid_labels_tj.csv\n",
      "Dataset saved: data/processed/tj/test\\test_data_tj.csv\n",
      "Dataset saved: data/processed/tj/test\\test_labels_tj.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the datasets\n",
    "datasets = {\n",
    "    \"cj\": {\"train\": (trd_cj, trl_cj), \"valid\": (vad_cj, val_cj), \"test\": (ted_cj, tel_cj)},\n",
    "    \"sj\": {\"train\": (trd_sj, trl_sj), \"valid\": (vad_sj, val_sj), \"test\": (ted_sj, tel_sj)},\n",
    "    \"tj\": {\"train\": (trd_tj, trl_tj), \"valid\": (vad_tj, val_tj), \"test\": (ted_tj, tel_tj)}\n",
    "}\n",
    "\n",
    "for key, splits in datasets.items():\n",
    "    for split, (data, labels) in splits.items():\n",
    "        utils.save_data_csv(data, f\"data/processed/{key}/{split}\", f\"{split}_data_{key}.csv\")\n",
    "        utils.save_data_csv(labels, f\"data/processed/{key}/{split}\", f\"{split}_labels_{key}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf824ef-2935-4b72-b985-ddf0dd7bc85e",
   "metadata": {},
   "source": [
    "#### Reordering the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8db10e4-1428-46dd-9bcd-8528e10dbceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the new order for the datasets\n",
    "new_order = [\n",
    "    'Time Phase', 'Cycle Time',\n",
    "    *[f'Current_J{i}' for i in range(6)],\n",
    "    *[f'Current_Direction_J{i}' for i in range(6)],\n",
    "    *[f'Speed_J{i}' for i in range(6)],\n",
    "    *[f'Speed_Direction_J{i}' for i in range(6)],\n",
    "    'Temperature_T0', *[f'Temperature_J{i}' for i in range(1, 6)],\n",
    "    'Average Temperature', 'Gradient Temperature', 'Load Imbalance'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da61123-32bf-4f78-8ff7-d68f9c9a0d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the datasets\n",
    "trd_cj = trd_cj[new_order]\n",
    "vad_cj = vad_cj[new_order]\n",
    "ted_cj = ted_cj[new_order]\n",
    "\n",
    "trd_sj = trd_sj[new_order]\n",
    "vad_sj = vad_sj[new_order]\n",
    "ted_sj = ted_sj[new_order]\n",
    "\n",
    "trd_tj = trd_tj[new_order]\n",
    "vad_tj = vad_tj[new_order]\n",
    "ted_tj = ted_tj[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d0873b-3dd8-4031-a6e6-e103c0847560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved: data/processed/cj/train\\scaled_train_data_cj.csv\n",
      "Dataset saved: data/processed/cj/valid\\scaled_valid_data_cj.csv\n",
      "Dataset saved: data/processed/cj/test\\scaled_test_data_cj.csv\n",
      "Dataset saved: data/processed/sj/train\\scaled_train_data_sj.csv\n",
      "Dataset saved: data/processed/sj/valid\\scaled_valid_data_sj.csv\n",
      "Dataset saved: data/processed/sj/test\\scaled_test_data_sj.csv\n",
      "Dataset saved: data/processed/tj/train\\scaled_train_data_tj.csv\n",
      "Dataset saved: data/processed/tj/valid\\scaled_valid_data_tj.csv\n",
      "Dataset saved: data/processed/tj/test\\scaled_test_data_tj.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the datasets\n",
    "datasets = {\n",
    "    \"cj\": {\"train\": trd_cj, \"valid\": vad_cj, \"test\": ted_cj},\n",
    "    \"sj\": {\"train\": trd_sj, \"valid\": vad_sj, \"test\": ted_sj},\n",
    "    \"tj\": {\"train\": trd_tj, \"valid\": vad_tj, \"test\": ted_tj}\n",
    "}\n",
    "\n",
    "for key, splits in datasets.items():\n",
    "    for split, data in splits.items():\n",
    "        utils.save_data_csv(data, f\"data/processed/{key}/{split}\", f\"scaled_{split}_data_{key}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d3a4496-5208-40cb-87a8-3c44cc2865f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the datasets\n",
    "for key, splits in datasets.items():\n",
    "    for split, data in splits.items():\n",
    "        datasets[key][split] = data[new_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbaab30-cafd-45fb-8294-c166ad2326d2",
   "metadata": {},
   "source": [
    "#### Creating sequences from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e201a079-c901-4b3c-99ea-8b81b34d876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the sequence length value\n",
    "with open(\"data/processed/sequence_length.txt\", \"r\") as file:\n",
    "    sequence_length = int(file.read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c96e26b6-e51e-4ee7-b017-d5923452e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sequences for training, validation, and test datasets\n",
    "trd_cj, trl_cj = utils.create_sequences(trd_cj, trl_cj, sequence_length, \"regression\")\n",
    "vad_cj, val_cj = utils.create_sequences(vad_cj, val_cj, sequence_length, \"regression\")\n",
    "ted_cj, tel_cj = utils.create_sequences(ted_cj, tel_cj, sequence_length, \"regression\")\n",
    "\n",
    "trd_sj, trl_sj = utils.create_sequences(trd_sj, trl_sj, sequence_length, \"regression\")\n",
    "vad_sj, val_sj = utils.create_sequences(vad_sj, val_sj, sequence_length, \"regression\")\n",
    "ted_sj, tel_sj = utils.create_sequences(ted_sj, tel_sj, sequence_length, \"regression\")\n",
    "\n",
    "trd_tj, trl_tj = utils.create_sequences(trd_tj, trl_tj, sequence_length, \"regression\")\n",
    "vad_tj, val_tj = utils.create_sequences(vad_tj, val_tj, sequence_length, \"regression\")\n",
    "ted_tj, tel_tj = utils.create_sequences(ted_tj, tel_tj, sequence_length, \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9587706-6bea-4586-80fc-a0d9d548dc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data \"Current joints\": (4742, 30, 35), Train labels \"Current joints\": (4742, 6)\n",
      "Valid data \"Current joints\": (1707, 30, 35), Valid labels \"Current joints\": (1707, 6)\n",
      "Test data \"Current joints\": (869, 30, 35), Test labels \"Current joints\": (869, 6)\n",
      "Train data \"Speed joints\": (4742, 30, 35), Train labels \"Speed joints\": (4742, 6)\n",
      "Valid data \"Speed joints\": (1707, 30, 35), Valid labels \"Speed joints\": (1707, 6)\n",
      "Test data \"Speed joints\": (869, 30, 35), Test labels \"Speed joints\": (869, 6)\n",
      "Train data \"Temperature joints\": (4742, 30, 35), Train labels \"Temperature joints\": (4742, 6)\n",
      "Valid data \"Temperature joints\": (1707, 30, 35), Valid labels \"Temperature joints\": (1707, 6)\n",
      "Test data \"Temperature joints\": (869, 30, 35), Test labels \"Temperature joints\": (869, 6)\n"
     ]
    }
   ],
   "source": [
    "# Checking if the sequences are created properly\n",
    "datasets = {\n",
    "    'Current joints': [trd_cj, trl_cj, vad_cj, val_cj, ted_cj, tel_cj],\n",
    "    'Speed joints': [trd_sj, trl_sj, vad_sj, val_sj, ted_sj, tel_sj],\n",
    "    'Temperature joints': [trd_tj, trl_tj, vad_tj, val_tj, ted_tj, tel_tj]\n",
    "}\n",
    "\n",
    "for label, (x_train, y_train, x_valid, y_valid, x_test, y_test) in datasets.items():\n",
    "    print(f\"Train data \\\"{label}\\\": {x_train.shape}, Train labels \\\"{label}\\\": {y_train.shape}\")\n",
    "    print(f\"Valid data \\\"{label}\\\": {x_valid.shape}, Valid labels \\\"{label}\\\": {y_valid.shape}\")\n",
    "    print(f\"Test data \\\"{label}\\\": {x_test.shape}, Test labels \\\"{label}\\\": {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5d37c45-dde9-4056-9462-72cea7a74cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sequences to: data\\processed\\cj\\train\\sequences\n",
      "Saved sequences to: data\\processed\\cj\\valid\\sequences\n",
      "Saved sequences to: data\\processed\\cj\\test\\sequences\n",
      "Saved sequences to: data\\processed\\sj\\train\\sequences\n",
      "Saved sequences to: data\\processed\\sj\\valid\\sequences\n",
      "Saved sequences to: data\\processed\\sj\\test\\sequences\n",
      "Saved sequences to: data\\processed\\tj\\train\\sequences\n",
      "Saved sequences to: data\\processed\\tj\\valid\\sequences\n",
      "Saved sequences to: data\\processed\\tj\\test\\sequences\n"
     ]
    }
   ],
   "source": [
    "# Saving the numpy arrays\n",
    "arrays = {\n",
    "    \"cj\": {\"train\": (trd_cj, trl_cj), \"valid\": (vad_cj, val_cj), \"test\": (ted_cj, tel_cj)},\n",
    "    \"sj\": {\"train\": (trd_sj, trl_sj), \"valid\": (vad_sj, val_sj), \"test\": (ted_sj, tel_sj)},\n",
    "    \"tj\": {\"train\": (trd_tj, trl_tj), \"valid\": (vad_tj, val_tj), \"test\": (ted_tj, tel_tj)}\n",
    "}\n",
    "\n",
    "for key, splits in arrays.items():\n",
    "    for split, data in splits.items():\n",
    "        folder = f\"data/processed/{key}/{split}/sequences\"\n",
    "        utils.save_sequences(data, folder, f\"seq_{split}_data_{key}.npy\", f\"seq_{split}_labels_{key}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "051d854f-d44a-4097-aacd-9cb71b33cf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeing up memory\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
